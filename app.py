# app.py

import torch
torch.set_num_threads(1) # æˆ–è€…ä¸€å€‹è¼ƒå°çš„å€¼ï¼Œå¦‚ 2 æˆ– 4
import os
os.environ["OMP_NUM_THREADS"] = "1" # é€šå¸¸èˆ‡ torch.set_num_threads(1) æ•ˆæœé¡ä¼¼æˆ–äº’è£œ
import gradio as gr
import pandas as pd # å¦‚æœ app.py æœ¬èº«ä¸ç”¨ pandasï¼Œå¯ä»¥è€ƒæ…®ç§»é™¤ (ä½†ä¿ç•™ä¹Ÿç„¡å¦¨)
import os
from src.util.rag_pipeline import load_rag_components, get_rag_response_from_pipeline, df_map as rag_df_map_global_var
import src.util.rag_pipeline as rag_module # ä½¿ç”¨æ¨¡çµ„åä¾†å­˜å–å…¶å…¨åŸŸè®Šæ•¸

# --- 1. å¾ä½ çš„ RAG pipeline å’Œ multimodal æ¨¡çµ„åŒ¯å…¥å‡½å¼ ---
try:
    # å¾ rag_pipeline åŒ¯å…¥ df_mapï¼Œä¸¦åœ¨è¼‰å…¥å¾Œä½¿ç”¨
    from src.util.rag_pipeline import load_rag_components, get_rag_response_from_pipeline, df_map as rag_df_map_global
    print("æˆåŠŸå¾ src.util.rag_pipeline åŒ¯å…¥å‡½å¼å’Œ df_mapã€‚")
except ImportError as e:
    print(f"å¾ src.util.rag_pipeline åŒ¯å…¥å‡½å¼å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿ src/util/rag_pipeline.py æª”æ¡ˆå­˜åœ¨ï¼Œä¸¦ä¸” src å’Œ src/util è³‡æ–™å¤¾ä¸‹æœ‰ __init__.py æª”æ¡ˆã€‚")
    print(f"å¾ src.util.rag_pipeline åŒ¯å…¥å‡½å¼ã€df_map æˆ– LLM è¨­å®šå¤±æ•—: {e}")
    rag_df_map = None # Fallback
    def load_rag_components(): print("éŒ¯èª¤ï¼šload_rag_components æœªèƒ½è¼‰å…¥ã€‚")
    def get_rag_response_from_pipeline(query_text, chat_history_list_ignored, k=3):
        return "éŒ¯èª¤ï¼šRAG pipeline æœªèƒ½è¼‰å…¥ã€‚", [], []
    
try:
    from src.util.multimodal_module import load_sam_model, handle_image_analysis, load_vit_model
    print("æˆåŠŸå¾ src.util.multimodal_module åŒ¯å…¥å‡½å¼ã€‚")
except ImportError as e:
    print(f"å¾ src.util.multimodal_module åŒ¯å…¥å‡½å¼å¤±æ•—: {e}")
    def load_sam_model():
        print("éŒ¯èª¤ï¼šload_sam_model (ä¾†è‡ª multimodal_module) æœªèƒ½è¼‰å…¥ã€‚")
        return False
    def handle_image_analysis(uploaded_image_pil):
        if uploaded_image_pil:
            return uploaded_image_pil, "éŒ¯èª¤ï¼šhandle_image_analysis (ä¾†è‡ª multimodal_module) æœªèƒ½è¼‰å…¥ï¼Œè¿”å›åŸå§‹åœ–ç‰‡ã€‚"
        return None, "éŒ¯èª¤ï¼šhandle_image_analysis (ä¾†è‡ª multimodal_module) æœªèƒ½è¼‰å…¥ã€‚"

try:
    from src.util.database_utils import (
        init_supabase_client, get_or_create_user, 
        add_weight_log, get_weight_logs,
        add_diet_log, get_diet_logs,
        add_user_goal, get_user_goals
    )
    print("æˆåŠŸå¾ src.util.database_utils åŒ¯å…¥å‡½å¼ã€‚")
except ImportError as e:
    # ... (database_utils fallback) ...
    pass

try:
    from src.util.langchain_utils import init_langchain_components, query_user_database_with_langchain
    print("æˆåŠŸå¾ src.util.langchain_utils åŒ¯å…¥å‡½å¼ã€‚")
except ImportError as e:
    print(f"å¾ src.util.langchain_utils åŒ¯å…¥å‡½å¼å¤±æ•—: {e}")
    def init_langchain_components(): print("éŒ¯èª¤: init_langchain_components æœªèƒ½è¼‰å…¥ã€‚"); return False
    def query_user_database_with_langchain(query, user_id=None): return "éŒ¯èª¤: LangChain æŸ¥è©¢åŠŸèƒ½æœªèƒ½è¼‰å…¥ã€‚"


# --- 2. RAG ç‡Ÿé¤Šå¸«çš„ Gradio èŠå¤©ä»‹é¢è™•ç†å‡½å¼ ---
def handle_chat_interaction(user_message, chat_history_list_of_dicts):
    current_chat_session = chat_history_list_of_dicts + [{"role": "user", "content": user_message}]
    answer_text, sources, _ = get_rag_response_from_pipeline(user_message, [], k=3)
    current_chat_session.append({"role": "assistant", "content": answer_text})
    
    formatted_sources_json = []
    final_markdown_string_for_sources = "### è©³ç´°ä¾†æºé è¦½\n\n"
    if sources:
        for src in sources:
            source_item_json = {
                "ä¾†æºç·¨è™Ÿ": src.get("id", "N/A"), "é£Ÿå“åç¨±": src.get("food_name", "N/A"),
                "FAISS_ID": src.get("faiss_id", "N/A"), "å…§å®¹é è¦½": src.get("text_content", "")[:150] + "..."}
            formatted_sources_json.append(source_item_json)
            final_markdown_string_for_sources += f"--- ({src.get('id', 'N/A')}) ---\n"
            final_markdown_string_for_sources += f"**é£Ÿå“åç¨±:** {src.get('food_name', 'N/A')}\n\n"
            final_markdown_string_for_sources += f"**FAISS ID:** {src.get('faiss_id', 'N/A')}\n\n"
            final_markdown_string_for_sources += f"**åŸå§‹æ–‡æœ¬ (é è¦½):**\n```text\n{src.get('text_content', '')}\n```\n\n"
    else:
        formatted_sources_json = [{"message": "æœ¬æ¬¡æŸ¥è©¢ç„¡ç‰¹å®šåƒè€ƒè³‡æ–™ã€‚"}]
        final_markdown_string_for_sources = "æœ¬æ¬¡æŸ¥è©¢ç„¡ç‰¹å®šåƒè€ƒè³‡æ–™ã€‚"
    return current_chat_session, formatted_sources_json, final_markdown_string_for_sources, ""

# --- 3. å€‹äººåŒ–é•·æœŸæ¸›è„‚æ•™ç·´çš„è™•ç†å‡½å¼ (ä½”ä½) ---
def handle_coach_interaction(username_input, weight_input_str, diet_log_input):
    if not username_input:
        return "è«‹è¼¸å…¥ç”¨æˆ¶åã€‚", "ç„¡æ­·å²é«”é‡è¨˜éŒ„ã€‚", "ç„¡é£²é£Ÿæ—¥èªŒè¨˜éŒ„ã€‚"

    user_data, error = get_or_create_user(username_input)
    if error:
        return f"ç”¨æˆ¶æ“ä½œå¤±æ•—: {error}", "", ""
    
    user_id = user_data['user_id']
    
    # æ·»åŠ é«”é‡è¨˜éŒ„ (å¦‚æœæä¾›äº†)
    if weight_input_str:
        try:
            weight_kg = float(weight_input_str)
            _, error_weight = add_weight_log(user_id, weight_kg)
            if error_weight:
                print(f"æ·»åŠ é«”é‡è¨˜éŒ„è­¦å‘Š: {error_weight}")
        except ValueError:
            print(f"ç„¡æ•ˆçš„é«”é‡è¼¸å…¥: {weight_input_str}")
            
    # TODO: æ·»åŠ é£²é£Ÿæ—¥èªŒçš„é‚è¼¯ (add_diet_log)
    if diet_log_input:
        print(f"ç”¨æˆ¶ {username_input} (ID: {user_id}) è¨˜éŒ„é£²é£Ÿ: {diet_log_input}")
        # _, error_diet = add_diet_log(user_id, diet_log_input) # å‡è¨­æœ‰é€™å€‹å‡½å¼

    # ç²å–ä¸¦é¡¯ç¤ºæœ€è¿‘çš„é«”é‡è¨˜éŒ„
    recent_weights, error_get_weights = get_weight_logs(user_id, limit=5)
    weight_history_display = "æœ€è¿‘é«”é‡è¨˜éŒ„:\n"
    if error_get_weights:
        weight_history_display += f"  ç²å–å¤±æ•—: {error_get_weights}"
    elif recent_weights:
        for log in recent_weights:
            weight_history_display += f"  - {log['logged_at'][:10]}: {log['weight_kg']} kg\n"
    else:
        weight_history_display += "  æš«ç„¡è¨˜éŒ„ã€‚"
        
    # TODO: ç²å–ä¸¦é¡¯ç¤ºé£²é£Ÿæ—¥èªŒå’Œç›®æ¨™ï¼Œä¸¦ç”Ÿæˆ LLM å»ºè­°

    coach_advice = f"ä½ å¥½ {username_input}ï¼ä½ çš„è³‡æ–™å·²æ›´æ–°ã€‚(ç¤ºæ„)"
    diet_history_display = f"é£²é£Ÿæ—¥èªŒè¨˜éŒ„ (ç¤ºæ„):\n - {diet_log_input if diet_log_input else 'æš«ç„¡æœ¬æ¬¡è¨˜éŒ„'}"

    return coach_advice, weight_history_display, diet_history_display

def handle_coach_submit_all_data(username_input, weight_input_str, meal_type_input, diet_description_input, calorie_input_str,
                                 goal_description_input, goal_type_input, goal_value_input, goal_target_date_input):
    # ... (ä½ ä¹‹å‰ç²å–æˆ–å‰µå»º user_data, user_id çš„é‚è¼¯ï¼Œä»¥åŠæ·»åŠ é«”é‡ã€é£²é£Ÿã€ç›®æ¨™åˆ°è³‡æ–™åº«çš„é‚è¼¯ä¿æŒä¸è®Š) ...
    if not username_input: # åŸºæœ¬çš„ç”¨æˆ¶åæª¢æŸ¥
        return "è«‹è¼¸å…¥ç”¨æˆ¶åã€‚", "", "", "", "ç”¨æˆ¶åç‚ºç©º"
    
    user_data, error = get_or_create_user(username_input)
    if error:
        return f"ç”¨æˆ¶æ“ä½œå¤±æ•—: {error}", "", "", "", f"ç”¨æˆ¶éŒ¯èª¤ - {error}"
    user_id = user_data['user_id']
    submission_status_parts = []

    # æ·»åŠ é«”é‡è¨˜éŒ„
    if weight_input_str:
        try:
            weight_kg = float(weight_input_str)
            _, error_weight = add_weight_log(user_id, weight_kg)
            if error_weight: submission_status_parts.append(f"é«”é‡è¨˜éŒ„è­¦å‘Š: {error_weight}")
            else: submission_status_parts.append("é«”é‡å·²è¨˜éŒ„")
        except ValueError:
            submission_status_parts.append(f"ç„¡æ•ˆé«”é‡: {weight_input_str}")
            
    # æ·»åŠ é£²é£Ÿæ—¥èªŒ
    if diet_description_input:
        calories = None
        if calorie_input_str:
            try: calories = float(calorie_input_str)
            except ValueError: submission_status_parts.append(f"é£²é£Ÿç†±é‡ç„¡æ•ˆ: {calorie_input_str}")
        _, error_diet = add_diet_log(user_id, diet_description_input, meal_type_input, calories)
        if error_diet: submission_status_parts.append(f"é£²é£Ÿè¨˜éŒ„è­¦å‘Š: {error_diet}")
        else: submission_status_parts.append("é£²é£Ÿå·²è¨˜éŒ„")

    # æ·»åŠ ç›®æ¨™
    if goal_description_input:
        _, error_goal = add_user_goal(user_id, goal_description_input, goal_type_input, goal_value_input, goal_target_date_input)
        if error_goal: submission_status_parts.append(f"ç›®æ¨™è¨­å®šè­¦å‘Š: {error_goal}")
        else: submission_status_parts.append("æ–°ç›®æ¨™å·²è¨­å®š")

    # --- ç”Ÿæˆ LLM æ•™ç·´å»ºè­° ---
    print(f"\næº–å‚™ç‚ºç”¨æˆ¶ {username_input} (ID: {user_id}) ç”Ÿæˆæ•™ç·´å»ºè­°...")
    recent_weights_for_llm, _ = get_weight_logs(user_id, days_limit=7)
    recent_diets_for_llm, _ = get_diet_logs(user_id, days_limit=7)
    active_goals_for_llm, _ = get_user_goals(user_id, status='active')

    user_data_summary = format_data_for_llm(username_input, recent_weights_for_llm, recent_diets_for_llm, active_goals_for_llm)

    # å¾ rag_module ä¸­ç²å–å·²åˆå§‹åŒ–çš„ LLM client å’Œ model name
    current_llm_client = rag_module.llm_client_global
    current_llm_model_name = rag_module.LLM_MODEL_NAME

    coach_advice_from_llm = generate_llm_coach_advice(user_data_summary, current_llm_client, current_llm_model_name) # << å‚³éåƒæ•¸
    # ------------------------

    # --- æ›´æ–°é¡¯ç¤ºçš„æ­·å²è¨˜éŒ„ (é€™éƒ¨åˆ†é‚è¼¯ä¿æŒä¸è®Šæˆ–ç•¥ä½œèª¿æ•´) ---
    weight_history_display = "æœ€è¿‘é«”é‡è¨˜éŒ„:\n"
    if recent_weights_for_llm: # ä½¿ç”¨å·²ç²å–çš„æ•¸æ“š
        for log in recent_weights_for_llm: weight_history_display += f"  - {log.get('logged_at','æœªçŸ¥')[:16]}: {log.get('weight_kg','N/A')} kg\n"
    else: weight_history_display += "  æš«ç„¡æœ€è¿‘7å¤©è¨˜éŒ„ã€‚"
        
    diet_history_display = "æœ€è¿‘é£²é£Ÿæ—¥èªŒ:\n"
    if recent_diets_for_llm: # ä½¿ç”¨å·²ç²å–çš„æ•¸æ“š
        for log in recent_diets_for_llm:
            cal_info = f" (ç´„ {log.get('estimated_calories', 'N/A')} å¤§å¡)" if log.get('estimated_calories') is not None else ""
            meal_info = f"{log.get('meal_type', '')}: " if log.get('meal_type') else ""
            diet_history_display += f"  - {log.get('logged_at','æœªçŸ¥')[:16]}: {meal_info}{log.get('description','')}{cal_info}\n"
    else: diet_history_display += "  æš«ç„¡æœ€è¿‘7å¤©è¨˜éŒ„ã€‚"

    goal_display = "é€²è¡Œä¸­ç›®æ¨™:\n"
    if active_goals_for_llm: # ä½¿ç”¨å·²ç²å–çš„æ•¸æ“š
        for goal in active_goals_for_llm:
            target_info = f" (ç›®æ¨™å€¼: {goal.get('target_value', 'N/A')})" if goal.get('target_value') else ""
            goal_display += f"  - [{goal.get('goal_type','é€šç”¨')}] {goal.get('description','')}{target_info}\n"
    else: goal_display += "  æš«ç„¡é€²è¡Œä¸­ç›®æ¨™ã€‚"
    
    final_submission_status = "æ—¥èªŒ/ç›®æ¨™æäº¤ç‹€æ…‹ï¼š" + ("; ".join(submission_status_parts) if submission_status_parts else "ç„¡æ–°æ“ä½œåŸ·è¡Œ")

    # å°‡ LLM ç”Ÿæˆçš„å»ºè­°é¡¯ç¤ºåœ¨ coach_advice_output
    return coach_advice_from_llm, weight_history_display, diet_history_display, goal_display, final_submission_status

def format_data_for_llm(username, weight_logs, diet_logs, active_goals):
    """å°‡å¾è³‡æ–™åº«ç²å–çš„æ•¸æ“šæ ¼å¼åŒ–ç‚º LLM prompt çš„ä¸€éƒ¨åˆ†"""
    prompt_parts = [f"é€™æ˜¯ä½¿ç”¨è€…ã€Œ{username}ã€çš„è¿‘æœŸå¥åº·è¨˜éŒ„ï¼š\n"]

    prompt_parts.append("# éå»7å¤©é£²é£Ÿæ‘˜è¦ï¼š")
    if diet_logs:
        for log in diet_logs:
            cal_info = f" (ç´„ {log.get('estimated_calories', 'æœªè¨˜éŒ„')} å¤§å¡)" if log.get('estimated_calories') is not None else ""
            meal_info = f"{log.get('meal_type', '')}: " if log.get('meal_type') else ""
            log_date = log.get('logged_at', 'æœªçŸ¥æ—¥æœŸ')[:10] # åªå–æ—¥æœŸéƒ¨åˆ†
            prompt_parts.append(f"- {log_date} {meal_info}{log.get('description', 'ç„¡æè¿°')}{cal_info}")
    else:
        prompt_parts.append("- éå»7å¤©é£²é£Ÿè¨˜éŒ„è¼ƒå°‘æˆ–æœªæä¾›ã€‚")
    prompt_parts.append("\n")

    prompt_parts.append("# éå»7å¤©é«”é‡è®ŠåŒ–ï¼š")
    if weight_logs:
        for log in weight_logs:
            log_date = log.get('logged_at', 'æœªçŸ¥æ—¥æœŸ')[:10]
            prompt_parts.append(f"- {log_date}: {log.get('weight_kg', 'æœªè¨˜éŒ„')} kg")
    else:
        prompt_parts.append("- éå»7å¤©é«”é‡è¨˜éŒ„è¼ƒå°‘æˆ–æœªæä¾›ã€‚")
    prompt_parts.append("\n")

    prompt_parts.append("# ç›®å‰è¨­å®šçš„ç›®æ¨™ï¼š")
    if active_goals:
        for goal in active_goals:
            target_info = f" (ç›®æ¨™å€¼: {goal.get('target_value', 'æœªè¨­å®š')})" if goal.get('target_value') else ""
            type_info = f"[{goal.get('goal_type', 'é€šç”¨')}] " if goal.get('goal_type') else ""
            prompt_parts.append(f"- {type_info}{goal.get('description', 'ç„¡æè¿°')}{target_info}")
    else:
        prompt_parts.append("- ç›®å‰æœªè¨­å®šæ˜ç¢ºç›®æ¨™ã€‚")
    
    return "\n".join(prompt_parts)

def generate_llm_coach_advice(user_data_summary_text, client, model_to_use):
    """å‘¼å« LLM ç”Ÿæˆæ•™ç·´å»ºè­°"""
    if not client or not model_to_use: # << ä¿®æ”¹åˆ¤æ–·æ¢ä»¶
        print("LLM å®¢æˆ¶ç«¯æˆ–æ¨¡å‹åç¨±æœªæ­£ç¢ºå‚³éï¼Œç„¡æ³•ç”Ÿæˆå»ºè­°ã€‚")
        return "æŠ±æ­‰ï¼ŒAI æ•™ç·´æš«æ™‚ç„¡æ³•æä¾›å»ºè­°ï¼ˆæ¨¡å‹é…ç½®éŒ¯èª¤ï¼‰ã€‚"

    system_prompt = "ä½ æ˜¯ä¸€ä½å°ˆæ¥­ä¸”å¯Œæœ‰åŒç†å¿ƒçš„æ¸›é‡èˆ‡å¥åº·æ•™ç·´ã€‚"
    user_task_prompt = f"""{user_data_summary_text}

è«‹æ ¹æ“šä»¥ä¸Šè³‡è¨Šï¼Œå®Œæˆä»¥ä¸‹ä»»å‹™ï¼š
1.  å°ä½¿ç”¨è€…éå»7å¤©çš„é£²é£Ÿå’Œé«”é‡è®ŠåŒ–ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰åšä¸€å€‹ç°¡çŸ­çš„å›é¡§èˆ‡ç¸½çµï¼ˆç´„100-150å­—ï¼‰ã€‚
2.  æ ¹æ“šä»–çš„è¨˜éŒ„å’Œç¾æœ‰ç›®æ¨™ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰ï¼Œç‚ºä»–è¨­å®šæ¥ä¸‹ä¾†ä¸€é€±çš„3å€‹å…·é«”çš„ã€å¯è¡¡é‡çš„ã€å¯é”æˆçš„ã€ç›¸é—œçš„ã€æœ‰æ™‚é™çš„ (SMART) å¥åº·ç›®æ¨™ã€‚ç›®æ¨™æ‡‰å…·é«”å¯è¡Œï¼Œä¸¦å…·é¼“å‹µæ€§ã€‚
è«‹ä»¥å°ˆæ¥­ä¸”å‹å–„çš„èªæ°£æä¾›å›é¥‹ã€‚
"""
    try:
        print(f"å‘ LLM ({model_to_use}) ç™¼é€è«‹æ±‚ä»¥ç”Ÿæˆæ•™ç·´å»ºè­°...")
        chat_completion = client.chat.completions.create( # << ä½¿ç”¨å‚³å…¥çš„ client
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_task_prompt}
            ],
            model=model_to_use, # << ä½¿ç”¨å‚³å…¥çš„ model_to_use
        )
        advice = chat_completion.choices[0].message.content
        print("LLM æ•™ç·´å»ºè­°ç”ŸæˆæˆåŠŸã€‚")
        return advice
    except Exception as e:
        print(f"å‘¼å« LLM ç”Ÿæˆæ•™ç·´å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        # ... (traceback)
        return f"æŠ±æ­‰ï¼Œç”Ÿæˆ AI æ•™ç·´å»ºè­°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"

# --- æ–°å¢ï¼šè™•ç† LangChain æ­·å²æ•¸æ“šæŸ¥è©¢çš„å‡½å¼ ---
def handle_langchain_history_query(username_input, history_query_input):
    if not username_input:
        return "è«‹å…ˆåœ¨ä¸Šæ–¹è¼¸å…¥æ‚¨çš„ç”¨æˆ¶åã€‚"
    if not history_query_input:
        return "è«‹è¼¸å…¥æ‚¨æƒ³æŸ¥è©¢çš„æ­·å²æ•¸æ“šå•é¡Œã€‚"

    user_data, error = get_or_create_user(username_input) # è¤‡ç”¨ä¹‹å‰çš„å‡½å¼ç²å– user_id
    if error or not user_data:
        return f"ç„¡æ³•è­˜åˆ¥ç”¨æˆ¶ã€Œ{username_input}ã€æˆ–ç²å–ç”¨æˆ¶IDå¤±æ•—ã€‚"
    
    user_id = user_data['user_id']
    
    # å‘¼å« LangChain çš„æŸ¥è©¢å‡½å¼
    answer = query_user_database_with_langchain(history_query_input, user_id)
    return answer

# --- 4. Gradio UI with Blocks and Tabs ---
with gr.Blocks(theme=gr.themes.Soft(primary_hue="teal", secondary_hue="orange"), title="å°ˆæ¥­æ¸›é‡è¼”åŠ©ç³»çµ±") as demo:
    gr.Markdown("# ğŸ¥— å°ˆæ¥­å‡é‡AIç‡Ÿé¤Šå¸« ğŸ§‘â€âš•ï¸") # æ‡‰ç”¨ç¨‹å¼ç¸½æ¨™é¡Œ

    df_map_state = gr.State(None) # åˆå§‹åŒ–ä¸€å€‹ State ä¾†å„²å­˜ df_map

    with gr.Tabs():
        # --- åˆ†é ä¸€ï¼šRAG ç‡Ÿé¤Šå¸« ---
        with gr.TabItem("RAGç‡Ÿé¤Šå¸«"):
            gr.Markdown("### ğŸ¤– AI ç‡Ÿé¤Šå¸«")
            gr.Markdown("è¼¸å…¥æ‚¨é—œæ–¼é£Ÿå“ç‡Ÿé¤Šçš„å•é¡Œï¼Œç³»çµ±å°‡æ ¹æ“šè³‡æ–™åº«æä¾›å›ç­”èˆ‡åƒè€ƒä¾†æºã€‚")
            with gr.Row():
                with gr.Column(scale=2):
                    rag_chatbot_display = gr.Chatbot(
                        label="èŠå¤©è¦–çª—", type='messages', height=600,
                        avatar_images=(None, "https://img.icons8.com/fluency/96/robot.png")
                    )
                    rag_user_input_textbox = gr.Textbox(
                        label="è¼¸å…¥æ‚¨çš„å•é¡Œï¼š", placeholder="ä¾‹å¦‚ï¼šé¦™è•‰çš„ç†±é‡æœ‰å¤šå°‘ï¼Ÿ", lines=1
                    )
                    rag_submit_button = gr.Button("ğŸ’¬ ç™¼é€è¨Šæ¯ (ç‡Ÿé¤Šå¸«)", variant="primary")
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“– åƒè€ƒè³‡æ–™")
                    rag_sources_json_output = gr.JSON(label="JSON æ ¼å¼ä¾†æº")
                    gr.Markdown("---")
                    gr.Markdown("#### è©³ç´°ä¾†æºé è¦½ (Markdown)")
                    rag_sources_md_output_area = gr.Markdown(label="ä¾†æºå…§å®¹æ‘˜è¦")
            
            rag_chat_state = gr.State([]) 
            df_map_state = gr.State(None)

            rag_submit_button.click(
                fn=handle_chat_interaction, 
                inputs=[rag_user_input_textbox, rag_chat_state], 
                outputs=[rag_chat_state, rag_sources_json_output, rag_sources_md_output_area, rag_user_input_textbox]
            ).then(
                lambda history: history, inputs=[rag_chat_state], outputs=[rag_chatbot_display]
            )
            rag_user_input_textbox.submit(
                fn=handle_chat_interaction, 
                inputs=[rag_user_input_textbox, rag_chat_state], 
                outputs=[rag_chat_state, rag_sources_json_output, rag_sources_md_output_area, rag_user_input_textbox]
            ).then(
                lambda history: history, inputs=[rag_chat_state], outputs=[rag_chatbot_display]
            )

        # --- åˆ†é äºŒï¼šæ‹ç…§ä¼°ç®—ç†±é‡ ---
        with gr.TabItem("æ‹ç…§ä¼°ç®—ç†±é‡"):
            gr.Markdown("### ğŸ“¸ æ‹ç…§ä¼°ç®—ç†±é‡èˆ‡èœå–®å»ºè­°")
            gr.Markdown("ä¸Šå‚³æ‚¨çš„é¤é»ç…§ç‰‡ï¼Œç³»çµ±å°‡å˜—è©¦åˆ†å‰²é£Ÿæä¸¦ç‚ºå¾ŒçºŒç†±é‡ä¼°ç®—åšæº–å‚™ã€‚")
            with gr.Row():
                with gr.Column(scale=1):
                    mm_input_image = gr.Image(type="pil", label="ä¸Šå‚³é¤é»ç…§ç‰‡", sources=["upload", "webcam", "clipboard"], height=400)
                    mm_process_button = gr.Button("ğŸ” é–‹å§‹åˆ†æåœ–ç‰‡", variant="primary")
                with gr.Column(scale=1):
                    gr.Markdown("#### åˆ†æçµæœ")
                    mm_output_annotated_image = gr.Image(label="å½±åƒåˆ†å‰²çµæœ", height=400)
                    mm_status_textbox = gr.Textbox(label="è™•ç†ç‹€æ…‹", interactive=False)
            
            # æ–°å¢ä¸€å€‹ Gallery å…ƒä»¶ä¾†å±•ç¤ºè£å‰ªå‡ºä¾†çš„é£Ÿæåœ–ç‰‡ (å¯é¸ï¼Œä½œç‚ºåˆæ­¥å±•ç¤º)
            gr.Markdown("---")
            gr.Markdown("#### æå–çš„é£Ÿæå€åŸŸ (ç¤ºæ„)")
            mm_cropped_gallery = gr.Gallery(label="æå–çš„é£Ÿæåœ–åƒ", height=200, columns=5, object_fit="contain")
            
            mm_process_button.click(
            fn=handle_image_analysis,
            inputs=[mm_input_image], # << å°‡ df_map_state ä½œç‚ºè¼¸å…¥
            outputs=[mm_output_annotated_image, mm_status_textbox, mm_cropped_gallery] # å‡è¨­ handle_image_analysis ç¾åœ¨å›å‚³3å€‹å€¼
            )

        # --- åˆ†é ä¸‰ï¼šå€‹äººæ¸›è„‚æ•™ç·´ ---
        with gr.TabItem("å€‹äººæ¸›è„‚æ•™ç·´"):
            gr.Markdown("### ğŸ’ª å€‹äººåŒ–é•·æœŸæ¸›è„‚æ•™ç·´")
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("#### èº«ä»½èˆ‡è¨˜éŒ„")
                    coach_username_input = gr.Textbox(label="æ‚¨çš„ç”¨æˆ¶å (ä¾‹å¦‚ï¼šç‹å°æ˜)")
                    coach_weight_input = gr.Textbox(label="ä»Šæ—¥é«”é‡ (å…¬æ–¤ï¼Œä¾‹å¦‚ï¼š65.5)")
                    coach_meal_type_input = gr.Dropdown(label="é¤é»é¡å‹", choices=["æ—©é¤", "åˆé¤", "æ™šé¤", "é»å¿ƒ", "å…¶ä»–"], value="å…¶ä»–")
                    coach_diet_description_input = gr.Textbox(label="è¨˜éŒ„æ‚¨çš„é¤é»æè¿° (ä¾‹å¦‚ï¼šç‡•éº¥ç‰›å¥¶ï¼Œä¸€é¡†è˜‹æœ)", lines=2)
                    coach_calorie_input = gr.Textbox(label="è©²é¤é»ä¼°è¨ˆç†±é‡ (å¯é¸ï¼Œä¾‹å¦‚ï¼š350)")
                    
                    gr.Markdown("#### è¨­å®šæ–°ç›®æ¨™")
                    coach_goal_description_input = gr.Textbox(label="ç›®æ¨™æè¿° (ä¾‹å¦‚ï¼šæœ¬é€±é‹å‹•ä¸‰æ¬¡)", lines=2)
                    coach_goal_type_input = gr.Dropdown(label="ç›®æ¨™é¡å‹", choices=["é«”é‡ç›®æ¨™", "é‹å‹•ç›®æ¨™", "é£²é£Ÿç¿’æ…£ç›®æ¨™", "å…¶ä»–"], value="å…¶ä»–")
                    coach_goal_value_input = gr.Textbox(label="ç›®æ¨™å€¼ (ä¾‹å¦‚ï¼š60kg, 3æ¬¡/é€±, æ¯æ—¥å–æ°´2L)")
                    coach_goal_target_date_input = gr.Textbox(label="ç›®æ¨™æ—¥æœŸ (YYYY-MM-DDï¼Œå¯é¸)") # æˆ–è€…ä½¿ç”¨ gr. à¤¡à¥‡à¤Ÿpicker å¦‚æœ Gradio æ›´æ–°äº†
                    
                    coach_submit_button = gr.Button("ğŸ“ æäº¤è¨˜éŒ„ / è¨­å®šç›®æ¨™ / æ›´æ–°è³‡è¨Š", variant="primary")
                
                with gr.Column(scale=1):
                    gr.Markdown("#### æ•™ç·´åé¥‹èˆ‡æ—¥èªŒ")
                    coach_advice_output = gr.Textbox(label="æ•™ç·´å»ºè­°/ç‹€æ…‹", lines=3, interactive=False)
                    coach_submission_status_output = gr.Textbox(label="æ—¥èªŒ/ç›®æ¨™æäº¤ç‹€æ…‹", lines=2, interactive=False)
                    coach_weight_history_output = gr.Textbox(label="é«”é‡æ­·å²", lines=7, interactive=False)
                    coach_diet_history_output = gr.Textbox(label="é£²é£Ÿæ—¥èªŒæ‘˜è¦", lines=7, interactive=False)
                    coach_goals_output = gr.Textbox(label="é€²è¡Œä¸­ç›®æ¨™", lines=7, interactive=False)


            # --- æ–°å¢ï¼šLangChain æ­·å²æ•¸æ“šæŸ¥è©¢å€å¡Š ---
            gr.Markdown("---")
            gr.Markdown("#### ğŸ—£ï¸ èˆ‡ AI æ•™ç·´å°è©± (æŸ¥è©¢æ‚¨çš„æ­·å²æ•¸æ“š)")
            coach_history_query_input = gr.Textbox(label="å‘ AI æ•™ç·´æå•æ‚¨çš„æ­·å²è¨˜éŒ„ (ä¾‹å¦‚ï¼šæˆ‘ä¸Šé€±çš„å¹³å‡é«”é‡æ˜¯å¤šå°‘ï¼Ÿ)ï¼š", placeholder="è¼¸å…¥å•é¡Œ...")
            coach_history_query_button = gr.Button("ğŸ” æŸ¥è©¢æ­·å²")
            coach_history_query_output = gr.Markdown(label="AI æ•™ç·´çš„å›è¦† (åŸºæ–¼æ­·å²æ•¸æ“š)") # ä½¿ç”¨ Markdown ä»¥ä¾¿æ›´å¥½åœ°é¡¯ç¤ºæ ¼å¼

            # åŸæœ‰çš„æäº¤æŒ‰éˆ•äº‹ä»¶ç¶å®š
            coach_submit_button.click(
                fn=handle_coach_submit_all_data, # ä½ ä¹‹å‰çš„å‡½å¼ï¼Œç¾åœ¨å®ƒæœƒç”Ÿæˆ LLM å»ºè­°
                inputs=[coach_username_input, coach_weight_input, coach_meal_type_input, coach_diet_description_input, coach_calorie_input,
                        coach_goal_description_input, coach_goal_type_input, coach_goal_value_input, coach_goal_target_date_input],
                outputs=[coach_advice_output, coach_weight_history_output, coach_diet_history_output, coach_goals_output, coach_submission_status_output]
            )

            # æ–°å¢çš„ LangChain æŸ¥è©¢æŒ‰éˆ•äº‹ä»¶ç¶å®š
            coach_history_query_button.click(
                fn=handle_langchain_history_query,
                inputs=[coach_username_input, coach_history_query_input], # éœ€è¦ç”¨æˆ¶åä¾†ç¢ºå®š user_id
                outputs=[coach_history_query_output]
            )


# --- 5. ä¸»ç¨‹å¼å…¥å£ ---
if __name__ == "__main__":
    print("æº–å‚™å•Ÿå‹• Gradio æ‡‰ç”¨ç¨‹å¼...")
    
    # 1. åˆå§‹åŒ– Supabase Client (ä¾†è‡ª database_utils)
    if not init_supabase_client():
        print("è­¦å‘Šï¼šSupabase å®¢æˆ¶ç«¯æœªèƒ½åˆå§‹åŒ–ï¼")

    # 2. è¼‰å…¥ RAG å…ƒä»¶ (é€™ä¹Ÿæœƒåˆå§‹åŒ– RAG ä½¿ç”¨çš„ LLM client)
    print("å°‡å‘¼å« load_rag_components() ä¾†è¼‰å…¥ RAG æ ¸å¿ƒçµ„ä»¶...")
    load_rag_components() 
    
    # 3. åˆå§‹åŒ– LangChain å…ƒä»¶ (åŒ…æ‹¬ SQLDatabase å’Œ SQLDatabaseChain)
    print("å°‡å‘¼å« init_langchain_components() ä¾†è¨­å®š LangChain...")
    if not init_langchain_components():
        print("è­¦å‘Šï¼šLangChain å…ƒä»¶æœªèƒ½åˆå§‹åŒ–ï¼æ­·å²æ•¸æ“šæŸ¥è©¢åŠŸèƒ½å¯èƒ½å—é™ã€‚")
    
    # 4. è¼‰å…¥ SAM å’Œ ViT æ¨¡å‹ (å¦‚æœé‚„æ²’åœ¨å…¶ä»–åœ°æ–¹çš„åˆå§‹åŒ–å‡½å¼ä¸­åŒ…å«)
    from src.util.multimodal_module import load_sam_model, load_vit_model # å‡è¨­ä½ åŒ¯å…¥äº†
    print("å°‡å‘¼å« load_sam_model() å’Œ load_vit_model()...")
    load_sam_model() 
    load_vit_model()

    print("å•Ÿå‹• Gradio æœå‹™...")
    demo.launch(debug=True)